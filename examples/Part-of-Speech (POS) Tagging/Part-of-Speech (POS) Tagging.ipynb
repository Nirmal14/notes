{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech (POS) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package brown to /home/dimitry/arch/jupyter...\n[nltk_data]   Package brown is already up-to-date!\n[nltk_data] Downloading package universal_tagset to\n[nltk_data]     /home/dimitry/arch/jupyter...\n[nltk_data]   Package universal_tagset is already up-to-date!\n\nTotal number of sentences: 57340\n"
    }
   ],
   "source": [
    "nltk_data = os.getcwd()\n",
    "nltk.data.path.append(nltk_data)\n",
    "nltk.download(\"brown\", download_dir=nltk_data)\n",
    "nltk.download(\"universal_tagset\", download_dir=nltk_data)\n",
    "\n",
    "data = nltk.corpus.brown.tagged_sents(tagset=\"universal\")\n",
    "data = np.array([ [(word.lower(), tag) for word, tag in sentence] for sentence in data ])\n",
    "\n",
    "EOS_TOK = \"#EOS#\"\n",
    "UNK_TOK = \"#UNK#\"\n",
    "\n",
    "all_tags = [EOS_TOK, UNK_TOK, \"ADV\", \"NOUN\", \"ADP\", \"PRON\", \"DET\", \".\", \"PRT\", \"VERB\", \"X\", \"NUM\", \"CONJ\", \"ADJ\"]\n",
    "TAG_PAD = 0\n",
    "UNK_TAG = 1\n",
    "n_tags = len(all_tags)\n",
    "\n",
    "print(\"\\nTotal number of sentences:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Coverage = 0.9829356385507306\n"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25)\n",
    "\n",
    "word_counts = Counter()\n",
    "for sentence in data:\n",
    "    words, tags = zip(*sentence)\n",
    "    word_counts.update(words)\n",
    "\n",
    "all_words = [EOS_TOK, UNK_TOK] + list(list(zip(*word_counts.most_common(30000)))[0])\n",
    "WORD_PAD = 0\n",
    "UNK_WORD = 1\n",
    "n_words = len(all_words)\n",
    "\n",
    "print(\"Coverage =\", float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = defaultdict(lambda: UNK_WORD, { word: i for i, word in enumerate(all_words) })\n",
    "tag_to_id = { tag: i for i, tag in enumerate(all_tags) }\n",
    "\n",
    "def to_dataset(data, batch_size):\n",
    "    words, tags = zip(*[ zip(*sent) for sent in data ])\n",
    "\n",
    "    # convert words and tags to ids\n",
    "    words = [[ word_to_id[word] for word in words ] for words in words]\n",
    "    tags = [[ tag_to_id[tag] for tag in tags ] for tags in tags]\n",
    "\n",
    "    # create Dataset of varying-length sequences using RaggedTensors\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(( tf.ragged.constant(words), tf.ragged.constant(tags) ))\n",
    "    # convert RaggedTensors to regular Tensors (needed for padded_batch() below)\n",
    "    dataset = dataset.map(lambda x, y: (x, y))\n",
    "    # shuffle entire dataset\n",
    "    dataset = dataset.shuffle(len(words))\n",
    "    # create padded batches of same length\n",
    "    dataset = dataset.padded_batch(batch_size, padded_shapes=([None], [None]), padding_values=(WORD_PAD, TAG_PAD))\n",
    "    # convert tags to 1-hot encoded values\n",
    "    dataset = dataset.apply(lambda ds: ds.map( lambda x, y: (x, tf.one_hot(y, n_tags)) ))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "\n",
    "train_set = to_dataset(train_data, batch_size=BATCH_SIZE)\n",
    "test_set = to_dataset(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_categorical_crossentropy(y_true, y_pred):\n",
    "    k = y_pred.shape[-1]\n",
    "    y_true = tf.reshape(y_true, shape=(-1, k))\n",
    "    y_pred = tf.reshape(y_pred, shape=(-1, k))\n",
    "    \n",
    "    mask = y_true[:, TAG_PAD] != 1\n",
    "    y_true = tf.boolean_mask(y_true, mask)\n",
    "    y_pred = tf.boolean_mask(y_pred, mask)\n",
    "    \n",
    "    return keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "def masked_categorical_accuracy(y_true, y_pred):\n",
    "    k = y_pred.shape[-1]\n",
    "    y_true = tf.reshape(y_true, shape=(-1, k))\n",
    "    y_pred = tf.reshape(y_pred, shape=(-1, k))\n",
    "    \n",
    "    mask = y_true[:, TAG_PAD] != 1\n",
    "    y_true = tf.boolean_mask(y_true, mask)\n",
    "    y_pred = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "    return keras.metrics.categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_emb30k128_d7_6xconv1d256k2di_6xd3_lstm256d3_b64\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, None)]       0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, None, 128)    3840256     input_1[0][0]                    \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, None, 128)    0           embedding[0][0]                  \n__________________________________________________________________________________________________\nconv1d (Conv1D)                 (None, None, 256)    65792       dropout[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, None, 256)    0           conv1d[0][0]                     \n__________________________________________________________________________________________________\nconv1d_1 (Conv1D)               (None, None, 256)    131328      dropout_1[0][0]                  \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, None, 256)    0           conv1d_1[0][0]                   \n__________________________________________________________________________________________________\nconv1d_2 (Conv1D)               (None, None, 256)    131328      dropout_2[0][0]                  \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, None, 256)    0           conv1d_2[0][0]                   \n__________________________________________________________________________________________________\nconv1d_3 (Conv1D)               (None, None, 256)    131328      dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, None, 256)    0           conv1d_3[0][0]                   \n__________________________________________________________________________________________________\nconv1d_4 (Conv1D)               (None, None, 256)    131328      dropout_4[0][0]                  \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, None, 256)    0           conv1d_4[0][0]                   \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, None, 1408)   0           dropout[0][0]                    \n                                                                 dropout_1[0][0]                  \n                                                                 dropout_2[0][0]                  \n                                                                 dropout_3[0][0]                  \n                                                                 dropout_4[0][0]                  \n                                                                 dropout_5[0][0]                  \n__________________________________________________________________________________________________\nbidirectional (Bidirectional)   (None, None, 512)    3409920     concatenate[0][0]                \n__________________________________________________________________________________________________\ntime_distributed (TimeDistribut (None, None, 14)     7182        bidirectional[0][0]              \n==================================================================================================\nTotal params: 7,848,462\nTrainable params: 7,848,462\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "input = layers.Input(shape=(None,))\n",
    "inter_0 = input\n",
    "\n",
    "inter_0 = layers.Embedding(n_words, 128)(inter_0)\n",
    "inter_0 = layers.Dropout(.7)(inter_0)\n",
    "\n",
    "filters = 256\n",
    "dropout = .3\n",
    "inter_1 = layers.Conv1D (filters, kernel_size=2, padding=\"same\", dilation_rate= 1, activation=\"relu\")(inter_0)\n",
    "inter_1 = layers.Dropout(dropout)(inter_1)\n",
    "inter_2 = layers.Conv1D (filters, kernel_size=2, padding=\"same\", dilation_rate= 2, activation=\"relu\")(inter_1)\n",
    "inter_2 = layers.Dropout(dropout)(inter_2)\n",
    "inter_3 = layers.Conv1D (filters, kernel_size=2, padding=\"same\", dilation_rate= 4, activation=\"relu\")(inter_2)\n",
    "inter_3 = layers.Dropout(dropout)(inter_3)\n",
    "inter_4 = layers.Conv1D (filters, kernel_size=2, padding=\"same\", dilation_rate= 8, activation=\"relu\")(inter_3)\n",
    "inter_4 = layers.Dropout(dropout)(inter_4)\n",
    "inter_5 = layers.Conv1D (filters, kernel_size=2, padding=\"same\", dilation_rate=16, activation=\"relu\")(inter_4)\n",
    "inter_5 = layers.Dropout(dropout)(inter_5)\n",
    "inter_6 = layers.Conv1D (filters, kernel_size=2, padding=\"same\", dilation_rate=32, activation=\"relu\")(inter_5)\n",
    "inter_6 = layers.Dropout(dropout)(inter_6)\n",
    "\n",
    "inter_0 = layers.Concatenate()([inter_0, inter_1, inter_2, inter_3, inter_4, inter_5])\n",
    "inter_0 = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=.3))(inter_0)\n",
    "inter_0 = layers.TimeDistributed(layers.Dense(n_tags, activation=\"softmax\"))(inter_0)\n",
    "\n",
    "output = inter_0\n",
    "model = keras.models.Model(input, output,\n",
    "    name=\"model_emb30k128_d7_6xconv1d256k2di_6xd3_lstm256d3_b64\"\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "    loss=masked_categorical_crossentropy,\n",
    "    metrics=[masked_categorical_accuracy]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n672/672 [==============================] - 173s 257ms/step - loss: 0.3769 - masked_categorical_accuracy: 0.8761 - val_loss: 0.1029 - val_masked_categorical_accuracy: 0.9668\nEpoch 2/20\n672/672 [==============================] - 128s 190ms/step - loss: 0.1053 - masked_categorical_accuracy: 0.9660 - val_loss: 0.0796 - val_masked_categorical_accuracy: 0.9743\nEpoch 3/20\n672/672 [==============================] - 127s 189ms/step - loss: 0.0802 - masked_categorical_accuracy: 0.9740 - val_loss: 0.0707 - val_masked_categorical_accuracy: 0.9771\nEpoch 4/20\n672/672 [==============================] - 127s 189ms/step - loss: 0.0691 - masked_categorical_accuracy: 0.9775 - val_loss: 0.0672 - val_masked_categorical_accuracy: 0.9787\nEpoch 5/20\n672/672 [==============================] - 126s 187ms/step - loss: 0.0619 - masked_categorical_accuracy: 0.9797 - val_loss: 0.0654 - val_masked_categorical_accuracy: 0.9790\nEpoch 6/20\n672/672 [==============================] - 127s 189ms/step - loss: 0.0568 - masked_categorical_accuracy: 0.9812 - val_loss: 0.0636 - val_masked_categorical_accuracy: 0.9801\nEpoch 7/20\n672/672 [==============================] - 126s 188ms/step - loss: 0.0528 - masked_categorical_accuracy: 0.9825 - val_loss: 0.0645 - val_masked_categorical_accuracy: 0.9797\nEpoch 8/20\n672/672 [==============================] - 125s 185ms/step - loss: 0.0497 - masked_categorical_accuracy: 0.9834 - val_loss: 0.0624 - val_masked_categorical_accuracy: 0.9802\nEpoch 9/20\n672/672 [==============================] - 127s 188ms/step - loss: 0.0470 - masked_categorical_accuracy: 0.9842 - val_loss: 0.0626 - val_masked_categorical_accuracy: 0.9806\nEpoch 10/20\n672/672 [==============================] - 126s 187ms/step - loss: 0.0451 - masked_categorical_accuracy: 0.9850 - val_loss: 0.0630 - val_masked_categorical_accuracy: 0.9807\nEpoch 11/20\n672/672 [==============================] - 125s 187ms/step - loss: 0.0432 - masked_categorical_accuracy: 0.9855 - val_loss: 0.0638 - val_masked_categorical_accuracy: 0.9803\nEpoch 12/20\n672/672 [==============================] - 125s 185ms/step - loss: 0.0411 - masked_categorical_accuracy: 0.9862 - val_loss: 0.0640 - val_masked_categorical_accuracy: 0.9810\nEpoch 13/20\n672/672 [==============================] - 125s 185ms/step - loss: 0.0401 - masked_categorical_accuracy: 0.9863 - val_loss: 0.0640 - val_masked_categorical_accuracy: 0.9809\nEpoch 14/20\n672/672 [==============================] - 126s 187ms/step - loss: 0.0384 - masked_categorical_accuracy: 0.9869 - val_loss: 0.0665 - val_masked_categorical_accuracy: 0.9807\nEpoch 15/20\n672/672 [==============================] - 126s 188ms/step - loss: 0.0372 - masked_categorical_accuracy: 0.9873 - val_loss: 0.0662 - val_masked_categorical_accuracy: 0.9808\nEpoch 16/20\n672/672 [==============================] - 125s 186ms/step - loss: 0.0359 - masked_categorical_accuracy: 0.9877 - val_loss: 0.0664 - val_masked_categorical_accuracy: 0.9809\nEpoch 17/20\n672/672 [==============================] - 125s 187ms/step - loss: 0.0346 - masked_categorical_accuracy: 0.9881 - val_loss: 0.0659 - val_masked_categorical_accuracy: 0.9808\nEpoch 18/20\n672/672 [==============================] - 125s 185ms/step - loss: 0.0341 - masked_categorical_accuracy: 0.9882 - val_loss: 0.0681 - val_masked_categorical_accuracy: 0.9810\nEpoch 19/20\n672/672 [==============================] - 126s 187ms/step - loss: 0.0329 - masked_categorical_accuracy: 0.9887 - val_loss: 0.0692 - val_masked_categorical_accuracy: 0.9806\nEpoch 20/20\n672/672 [==============================] - 125s 186ms/step - loss: 0.0325 - masked_categorical_accuracy: 0.9887 - val_loss: 0.0687 - val_masked_categorical_accuracy: 0.9809\n"
    }
   ],
   "source": [
    "hist = model.fit(train_set,\n",
    "    epochs=20,\n",
    "    validation_data=test_set,\n",
    "    verbose=1,\n",
    "    callbacks=[keras.callbacks.TensorBoard(log_dir=\"logs/\" + model.name, profile_batch=0)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard](tensorboard.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "nteract": {
   "version": "nteract-on-jupyter@2.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}